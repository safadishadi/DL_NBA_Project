{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofxf80vLdj2U",
    "outputId": "6eaba738-8008-4286-ee39-d58990a6279a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nba_api\n",
      "  Downloading nba_api-1.7.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.2 in /usr/local/lib/python3.11/dist-packages (from nba_api) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from nba_api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2024.12.14)\n",
      "Downloading nba_api-1.7.0-py3-none-any.whl (280 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/280.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nba_api\n",
      "Successfully installed nba_api-1.7.0\n",
      "Fetching game data...\n",
      "Fetching team stats...\n",
      "Fetching player stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-ec1a50e8cf5a>:60: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(all_player_stats, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#TODO: remove all unneccessary debugand prints\n",
    "# Install necessary libraries\n",
    "!pip install nba_api\n",
    "\n",
    "from nba_api.stats.endpoints import leaguegamefinder, teamgamelog, playergamelog\n",
    "from nba_api.stats.static import teams, players\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import time\n",
    "\n",
    "# Step 1: Fetch NBA Stats\n",
    "def fetch_all_game_data():\n",
    "    \"\"\"\n",
    "    Fetches all NBA game data from the API for all teams.\n",
    "    Returns a DataFrame with historical game data.\n",
    "    \"\"\"\n",
    "    nba_teams = teams.get_teams()\n",
    "    all_games = []\n",
    "    for team in nba_teams:\n",
    "        team_id = team['id']\n",
    "        gamefinder = leaguegamefinder.LeagueGameFinder(team_id_nullable=team_id)\n",
    "        team_games = gamefinder.get_data_frames()[0]\n",
    "        team_games['TEAM_ID'] = team_id\n",
    "        all_games.append(team_games)\n",
    "        time.sleep(1)  # Prevent rate limiting\n",
    "    return pd.concat(all_games, ignore_index=True)\n",
    "\n",
    "def fetch_team_stats():\n",
    "    \"\"\"\n",
    "    Fetches team stats for all teams.\n",
    "    Returns a DataFrame with team stats.\n",
    "    \"\"\"\n",
    "    nba_teams = teams.get_teams()\n",
    "    all_team_stats = []\n",
    "    for team in nba_teams:\n",
    "        team_id = team['id']\n",
    "        stats = teamgamelog.TeamGameLog(team_id=team_id).get_data_frames()[0]\n",
    "        stats['TEAM_ID'] = team_id\n",
    "        all_team_stats.append(stats)\n",
    "        time.sleep(1)\n",
    "    return pd.concat(all_team_stats, ignore_index=True)\n",
    "\n",
    "def fetch_player_stats():\n",
    "    \"\"\"\n",
    "    Fetches player stats for all players.\n",
    "    Returns a DataFrame with player stats.\n",
    "    \"\"\"\n",
    "    nba_players = players.get_players()\n",
    "    all_player_stats = []\n",
    "    for player in nba_players[:50]:  # Limit to first 50 players to avoid overloading TODO:maybe remove\n",
    "        player_id = player['id']\n",
    "        try:\n",
    "            stats = playergamelog.PlayerGameLog(player_id=player_id).get_data_frames()[0]\n",
    "            stats['PLAYER_ID'] = player_id\n",
    "            all_player_stats.append(stats)\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching player stats for {player['full_name']}: {e}\")\n",
    "    return pd.concat(all_player_stats, ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"Fetching game data...\")\n",
    "games = fetch_all_game_data()\n",
    "\n",
    "print(\"Fetching team stats...\")\n",
    "team_stats = fetch_team_stats()\n",
    "\n",
    "print(\"Fetching player stats...\")\n",
    "player_stats = fetch_player_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oN-3BOFBRGbo"
   },
   "outputs": [],
   "source": [
    "# Step 2: Preprocess Data\n",
    "\n",
    "# helper function that checks if column includes any alphabetical characters\n",
    "def contains_alpha(col):\n",
    "    # Only apply to columns of type 'object' (string columns)\n",
    "    if col.dtype == 'object':\n",
    "        return col.str.contains(r'[a-zA-Z]', na=False).any()\n",
    "    return False\n",
    "\n",
    "# data preperation function that combines the columns into one dataframe, creates new features and deletes unwanted features\n",
    "def preprocess_data(games, team_stats, player_stats):\n",
    "    \"\"\"\n",
    "    Prepares and merges game, team, and player stats for use with a Tabular Transformer.\n",
    "    \"\"\"\n",
    "    # Merge games with team stats\n",
    "    data = games.merge(team_stats, left_on=['GAME_ID', 'TEAM_ID'], right_on=['Game_ID', 'Team_ID'], how='left', suffixes=('', '_TEAM'))\n",
    "\n",
    "    # Aggregate player stats by GAME_ID and TEAM_ID\n",
    "    \"\"\" temporarily removed, TODO: add back to model\n",
    "    player_stats_grouped = player_stats.groupby(['Game_ID', 'TEAM_ID']).mean().reset_index()\n",
    "    player_stats_grouped.drop(columns=['PLAYER_ID'], inplace=True)\n",
    "\n",
    "    # Merge aggregated player stats with games\n",
    "    data = data.merge(player_stats_grouped, on=['GAME_ID', 'TEAM_ID'], how='left', suffixes=('', '_PLAYER'))\n",
    "    \"\"\"\n",
    "    # Encode target variable (e.g., Win/Loss)\n",
    "    data['TARGET'] = (data['WL'] == 'W').astype(int)\n",
    "\n",
    "    # add new features\n",
    "    data['Home'] = data['MATCHUP'].apply(lambda x: 1 if '@' in x else 0)\n",
    "    data['Win_Streak'] = data.groupby('TEAM_ID')['W'].rolling(window=5).sum().reset_index(drop=True)\n",
    "    data['Win_Pct_Last_10'] = data.groupby('TEAM_ID')['W'].rolling(window=10).mean().reset_index(drop=True)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = ['GAME_DATE', 'MATCHUP', 'WL', 'GAME_ID', 'TEAM_ABBREVIATION', 'TEAM_NAME']\n",
    "    data.drop(columns=[col for col in columns_to_drop if col in data.columns], inplace=True)\n",
    "\n",
    "    print(type(data))\n",
    "    # Drop the columns with alphabetic characters\n",
    "    columns_to_drop2 = [col for col in data.columns if contains_alpha(data[col])]\n",
    "    print(columns_to_drop2)\n",
    "    print(type(data))\n",
    "    if(columns_to_drop2):\n",
    "      data.drop(columns=[col for col in columns_to_drop2 if col in data.columns], inplace=True)\n",
    "    print(type(data))\n",
    "\n",
    "    # Handle missing values\n",
    "    data.fillna(0, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Step 3: Prepare Data for Tabular Transformer, split to train/val/test, normalize values\n",
    "def prepare_data_for_transformer(data):\n",
    "    \"\"\"\n",
    "    Splits the data into train, validation, and test sets and scales numeric features.\n",
    "    \"\"\"\n",
    "    # Split data into features and target\n",
    "    X = data\n",
    "    y = data['TARGET']\n",
    "\n",
    "    # Split into train, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "    # Define features for Standard and MinMax normalization\n",
    "    standard_features = ['MIN', 'PTS', 'FGM', 'FGA', 'FG3M', 'FG3A', 'FTM', 'FTA', 'OREB', 'DREB', 'REB',\n",
    "                         'AST', 'STL', 'BLK', 'TOV', 'PF', 'PLUS_MINUS', 'MIN_TEAM', 'FGM_TEAM', 'FGA_TEAM',\n",
    "                         'FG3M_TEAM', 'FG3A_TEAM', 'FTM_TEAM', 'FTA_TEAM', 'OREB_TEAM', 'DREB_TEAM', 'REB_TEAM',\n",
    "                         'AST_TEAM', 'STL_TEAM', 'BLK_TEAM', 'TOV_TEAM', 'PF_TEAM', 'PTS_TEAM', 'Win_Streak']\n",
    "\n",
    "    minmax_features = ['FG_PCT', 'FG3_PCT', 'FT_PCT', 'Home', 'W', 'L', 'W_PCT', 'FG_PCT_TEAM',\n",
    "                       'FG3_PCT_TEAM', 'FT_PCT_TEAM', 'Win_Pct_Last_10']\n",
    "\n",
    "    print(type(X_train))\n",
    "    # Standard Scaling\n",
    "    standard_scaler = StandardScaler()\n",
    "    X_train[standard_features] = standard_scaler.fit_transform(X_train[standard_features])\n",
    "    X_val[standard_features] = standard_scaler.transform(X_val[standard_features])\n",
    "    X_test[standard_features] = standard_scaler.transform(X_test[standard_features])\n",
    "\n",
    "    print(type(X_train))\n",
    "    # MinMax Scaling\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    X_train[minmax_features] = minmax_scaler.fit_transform(X_train[minmax_features])\n",
    "    X_val[minmax_features] = minmax_scaler.transform(X_val[minmax_features])\n",
    "    X_test[minmax_features] = minmax_scaler.transform(X_test[minmax_features])\n",
    "    print(type(X_train))\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "OQuKIjWMBiPf",
    "outputId": "d2d0bbc8-89e1-4147-dcb7-167f8dbfb265"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' just for debugging TODO:remove cell\\nprint(games.columns)\\nprint(team_stats.columns)\\nprint(player_stats.columns)\\nprint(games.head())\\nprint(team_stats.head())\\nprint(player_stats.sample())\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" just for debugging TODO:remove cell\n",
    "print(games.columns)\n",
    "print(team_stats.columns)\n",
    "print(player_stats.columns)\n",
    "print(games.head())\n",
    "print(team_stats.head())\n",
    "print(player_stats.sample())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "Qbwz2s20fo_3",
    "outputId": "02aec55d-2b42-40c3-e762-3d0b36759517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "['GAME_DATE_TEAM', 'MATCHUP_TEAM', 'WL_TEAM']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Preparing data for Tabular Transformer...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "       SEASON_ID     TEAM_ID       MIN       PTS       FGM       FGA  \\\n",
      "39452      21991  1610612747 -0.033652 -0.164260  0.266745 -0.283549   \n",
      "102982     22000  1610612765 -0.033652  0.545335  0.431987 -0.058440   \n",
      "76543      22023  1610612758  2.000504  1.325890  0.597229  1.179659   \n",
      "16752      21990  1610612741 -0.033652  0.545335  0.927713 -0.283549   \n",
      "93582      41991  1610612762 -0.033652 -1.015775 -1.220433 -2.084420   \n",
      "...          ...         ...       ...       ...       ...       ...   \n",
      "102486     22005  1610612765 -0.115019 -0.093301  0.101503  0.391778   \n",
      "75696      21991  1610612757 -0.033652  1.325890  0.266745 -0.396103   \n",
      "19822      22000  1610612742  0.047714  0.403416 -0.063739 -0.733767   \n",
      "70141      22010  1610612756 -0.033652 -1.370572 -0.724707 -0.396103   \n",
      "50928      22021  1610612751  0.129080  2.106445  1.258197 -0.170994   \n",
      "\n",
      "          FG_PCT      FG3M      FG3A  FG3_PCT  ...  STL_TEAM  BLK_TEAM  \\\n",
      "39452   0.658667 -1.191680 -1.380874   0.1665  ... -0.109186 -0.104256   \n",
      "102982  0.658667  0.126940 -0.111096   0.2060  ... -0.109186 -0.104256   \n",
      "76543   0.596000  1.006021  1.521477   0.1570  ... -0.109186 -0.104256   \n",
      "16752   0.724000 -0.971910 -1.018080   0.1430  ... -0.109186 -0.104256   \n",
      "93582   0.636000 -1.191680 -1.108779   0.0835  ... -0.109186 -0.104256   \n",
      "...          ...       ...       ...      ...  ...       ...       ...   \n",
      "102486  0.597333 -0.092830  0.342397   0.1365  ... -0.109186 -0.104256   \n",
      "75696   0.666667 -0.752140 -0.745985   0.1500  ... -0.109186 -0.104256   \n",
      "19822   0.658667  0.346711  0.070301   0.2105  ... -0.109186 -0.104256   \n",
      "70141   0.566667 -1.191680 -0.201794   0.0315  ... -0.109186 -0.104256   \n",
      "50928   0.748000  2.544412  1.521477   0.2570  ... -0.109186 -0.104256   \n",
      "\n",
      "        TOV_TEAM   PF_TEAM  PTS_TEAM  TEAM_ID_TEAM  TARGET  Home  Win_Streak  \\\n",
      "39452  -0.111795 -0.113651 -0.115669           0.0       1   0.0   -0.092889   \n",
      "102982 -0.111795 -0.113651 -0.115669           0.0       1   1.0   -0.092889   \n",
      "76543  -0.111795 -0.113651 -0.115669           0.0       1   0.0   -0.092889   \n",
      "16752  -0.111795 -0.113651 -0.115669           0.0       1   0.0   -0.092889   \n",
      "93582  -0.111795 -0.113651 -0.115669           0.0       0   1.0   -0.092889   \n",
      "...          ...       ...       ...           ...     ...   ...         ...   \n",
      "102486 -0.111795 -0.113651 -0.115669           0.0       1   1.0   -0.092889   \n",
      "75696  -0.111795 -0.113651 -0.115669           0.0       1   0.0   -0.092889   \n",
      "19822  -0.111795 -0.113651 -0.115669           0.0       1   1.0   -0.092889   \n",
      "70141  -0.111795 -0.113651 -0.115669           0.0       0   0.0   -0.092889   \n",
      "50928  -0.111795 -0.113651 -0.115669           0.0       1   1.0   -0.092889   \n",
      "\n",
      "        Win_Pct_Last_10  \n",
      "39452               0.0  \n",
      "102982              0.0  \n",
      "76543               0.0  \n",
      "16752               0.0  \n",
      "93582               0.0  \n",
      "...                 ...  \n",
      "102486              0.0  \n",
      "75696               0.0  \n",
      "19822               0.0  \n",
      "70141               0.0  \n",
      "50928               0.0  \n",
      "\n",
      "[75304 rows x 51 columns]\n",
      "Data is ready!\n",
      "Train shape: (75304, 51), Validation shape: (16137, 51), Test shape: (16137, 51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'just for debugging TODO:remove from cell\\nprint(\"X_train columns\")\\nprint(X_train.columns)\\nprint(\"X_val columns\")\\nprint(X_val.columns)\\nprint(\"X_test columns\")\\nprint(X_test.columns)\\nprint(\"X_train head()\")\\nprint(X_train.head())\\nprint(\"X_val head()\")\\nprint(X_val.head())\\nprint(\"X_test head()\")\\nprint(X_test.head())\\nprint(\"y_train head()\")\\nprint(y_train.head())\\nprint(\"y_val head()\")\\nprint(y_val.head())\\nprint(\"y_test head()\")\\nprint(y_test.head())\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preserve original data, work on copies\n",
    "games_copy = games.copy()\n",
    "team_stats_copy = team_stats.copy()\n",
    "player_stats_copy = player_stats.copy()\n",
    "\n",
    "print(\"Preprocessing data...\")\n",
    "data = preprocess_data(games_copy, team_stats_copy, player_stats_copy)\n",
    "\n",
    "\"\"\"\n",
    "just for debugging TODO:remove from cell\n",
    "print(\"data columns\")\n",
    "print(data.columns)\n",
    "print(\"data head()\")\n",
    "print(data.head())\n",
    "\"\"\"\n",
    "\n",
    "print(\"Preparing data for Tabular Transformer...\")\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = prepare_data_for_transformer(data)\n",
    "print(X_train)#TODO:remove\n",
    "print(\"Data is ready!\")\n",
    "print(f\"Train shape: {X_train.shape}, Validation shape: {X_val.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "\n",
    "\"\"\"just for debugging TODO:remove from cell\n",
    "print(\"X_train columns\")\n",
    "print(X_train.columns)\n",
    "print(\"X_val columns\")\n",
    "print(X_val.columns)\n",
    "print(\"X_test columns\")\n",
    "print(X_test.columns)\n",
    "print(\"X_train head()\")\n",
    "print(X_train.head())\n",
    "print(\"X_val head()\")\n",
    "print(X_val.head())\n",
    "print(\"X_test head()\")\n",
    "print(X_test.head())\n",
    "print(\"y_train head()\")\n",
    "print(y_train.head())\n",
    "print(\"y_val head()\")\n",
    "print(y_val.head())\n",
    "print(\"y_test head()\")\n",
    "print(y_test.head())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "dbbd7b77393b4807a29de8c8d3a154d2",
      "717cf9cf0d6f4c0391e3a34cacd568d8",
      "b42bffb3289d49b499b0e4934609b8e5",
      "9214dcfdb51c4ff090c8e0158913dc4e"
     ]
    },
    "id": "yqUNhEntnI_3",
    "outputId": "83b3a049-08e5-4332-d68f-865363b55c3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-02 10:25:29,942] A new study created in memory with name: no-name-6cdb0fa6-c862-4c3d-b836-5fd883c3865f\n",
      "<ipython-input-6-d94592486e71>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
      "<ipython-input-6-d94592486e71>:14: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout = trial.suggest_uniform('dropout', 0.1, 0.5)\n",
      "INFO:pytorch_tabular.tabular_model:Experiment Tracking is turned off\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
      "INFO:pytorch_tabular.tabular_model:Preparing the DataLoaders\n",
      "INFO:pytorch_tabular.tabular_datamodule:Setting up the datamodule for classification task\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabular/tabular_datamodule.py:386: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.50930472  1.58980316  0.77348343 ... -1.09239024  0.54024922\n",
      " -0.0428363 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabular/tabular_datamodule.py:390: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.47318605  1.47318605 -0.97577314 ... -1.32562445 -1.09239024\n",
      " -0.62592182]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "INFO:pytorch_tabular.tabular_model:Preparing the Model: CategoryEmbeddingModel\n",
      "INFO:pytorch_tabular.tabular_model:Preparing the Trainer\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_tabular.tabular_model:Training Started\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /content/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 27.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │    100 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │    286 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss          │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 27.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │    100 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │    286 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss          │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 27.9 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 27.9 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 16                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 27.9 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 27.9 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 16                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbd7b77393b4807a29de8c8d3a154d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_tabular.tabular_model:Training the model completed\n",
      "INFO:pytorch_tabular.tabular_model:Loading the best model\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabular/tabular_datamodule.py:390: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.47318605  1.47318605 -0.97577314 ... -1.32562445 -1.09239024\n",
      " -0.62592182]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "[I 2025-02-02 10:35:41,943] Trial 0 finished with value: 0.9463964801388114 and parameters: {'learning_rate': 0.014623791481441733, 'dropout': 0.3926569304175621, 'hidden_layers': 2, 'hidden_dim': 142, 'batch_size': 32}. Best is trial 0 with value: 0.9463964801388114.\n",
      "<ipython-input-6-d94592486e71>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
      "<ipython-input-6-d94592486e71>:14: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout = trial.suggest_uniform('dropout', 0.1, 0.5)\n",
      "INFO:pytorch_tabular.tabular_model:Experiment Tracking is turned off\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
      "INFO:pytorch_tabular.tabular_model:Preparing the DataLoaders\n",
      "INFO:pytorch_tabular.tabular_datamodule:Setting up the datamodule for classification task\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TARGET_0_probability', 'TARGET_1_probability', 'TARGET_prediction'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabular/tabular_datamodule.py:386: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.50930472  1.58980316  0.77348343 ... -1.09239024  0.54024922\n",
      " -0.0428363 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.fit_transform(\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabular/tabular_datamodule.py:390: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.47318605  1.47318605 -0.97577314 ... -1.32562445 -1.09239024\n",
      " -0.62592182]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "INFO:pytorch_tabular.tabular_model:Preparing the Model: CategoryEmbeddingModel\n",
      "INFO:pytorch_tabular.tabular_model:Preparing the Trainer\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_tabular.tabular_model:Training Started\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /content/saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │ 19.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │    100 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │    144 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss          │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │ 19.0 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │    100 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │    144 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss          │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 19.2 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 19.2 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 22                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 19.2 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 19.2 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 22                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42bffb3289d49b499b0e4934609b8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_tabular.tabular_model:Training the model completed\n",
      "INFO:pytorch_tabular.tabular_model:Loading the best model\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabular/utils/python_utils.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n",
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabular/tabular_datamodule.py:390: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 1.47318605  1.47318605 -0.97577314 ... -1.32562445 -1.09239024\n",
      " -0.62592182]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.loc[:, self.config.continuous_cols] = self.scaler.transform(data.loc[:, self.config.continuous_cols])\n",
      "[I 2025-02-02 10:45:17,913] Trial 1 finished with value: 0.9518497862056144 and parameters: {'learning_rate': 0.0024417364316333913, 'dropout': 0.22804378369495684, 'hidden_layers': 4, 'hidden_dim': 71, 'batch_size': 64}. Best is trial 1 with value: 0.9518497862056144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TARGET_0_probability', 'TARGET_1_probability', 'TARGET_prediction'], dtype='object')\n",
      "Best Parameters: {'learning_rate': 0.0024417364316333913, 'dropout': 0.22804378369495684, 'hidden_layers': 4, 'hidden_dim': 71, 'batch_size': 64}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d94592486e71>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m final_model = TabularModel(\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mdata_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_model_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0moptimizer_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_optimizer_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_config' is not defined"
     ]
    }
   ],
   "source": [
    "# Uncomment to install necessary libraries\n",
    "#!pip install optuna pytorch-tabular\n",
    "\n",
    "import optuna\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Define the Objective Function\n",
    "def objective(trial):\n",
    "    # Hyperparameters to optimize\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
    "    dropout = trial.suggest_uniform('dropout', 0.1, 0.5)\n",
    "    hidden_layers = trial.suggest_int('hidden_layers', 1, 4)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 32, 256)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "\n",
    "    # Data Configuration\n",
    "    data_config = DataConfig(\n",
    "        target=['TARGET'],\n",
    "        continuous_cols=[col for col in data.columns if col != 'TARGET'],\n",
    "        categorical_cols=[],\n",
    "    )\n",
    "\n",
    "    # Model Configuration\n",
    "    model_config = CategoryEmbeddingModelConfig(\n",
    "        task=\"classification\",\n",
    "        layers=\"-\".join([str(hidden_dim)] * hidden_layers),\n",
    "        activation=\"ReLU\",\n",
    "        dropout=dropout,\n",
    "    )\n",
    "\n",
    "    # Trainer Configuration\n",
    "    trainer_config = TrainerConfig(\n",
    "        auto_lr_find=False,\n",
    "        batch_size=batch_size,\n",
    "        max_epochs=10,#originally was 20\n",
    "    )\n",
    "\n",
    "    # Optimizer Configuration\n",
    "    optimizer_config = OptimizerConfig(\n",
    "        optimizer=\"Adam\",\n",
    "    )\n",
    "\n",
    "    # Initialize the Tabular Model\n",
    "    tabular_model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=model_config,\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    tabular_model.fit(train=X_train, validation=X_val)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    preds = tabular_model.predict(X_val)\n",
    "    print(preds.columns)\n",
    "    accuracy = accuracy_score(y_val, preds['TARGET_prediction'])\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Step 2: Create Study and Optimize\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=2)#was 50 originally\n",
    "\n",
    "# Step 3: Train Final Model with Best Parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "data_config = DataConfig(\n",
    "        target=['TARGET'],\n",
    "        continuous_cols=[col for col in data.columns if col != 'TARGET'],\n",
    "        categorical_cols=[],\n",
    "    )\n",
    "\n",
    "final_model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"-\".join([str(best_params['hidden_dim'])] * best_params['hidden_layers']),\n",
    "    activation=\"ReLU\",\n",
    "    dropout=best_params['dropout'],\n",
    ")\n",
    "\n",
    "final_trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False,\n",
    "    batch_size=best_params['batch_size'],\n",
    "    max_epochs=30,\n",
    ")\n",
    "\n",
    "final_optimizer_config = OptimizerConfig(\n",
    "    optimizer=\"Adam\",\n",
    "    #learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "final_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=final_model_config,\n",
    "    optimizer_config=final_optimizer_config,\n",
    "    trainer_config=final_trainer_config\n",
    ")\n",
    "\n",
    "final_model.fit(train=X_train, validation=X_val)\n",
    "\n",
    "# Step 4: Evaluate on Test Set\n",
    "final_preds = final_model.predict(X_test)\n",
    "final_accuracy = accuracy_score(y_test, final_preds['TARGET_prediction'])\n",
    "\n",
    "print(f\"Final Test Accuracy: {final_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deep_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "717cf9cf0d6f4c0391e3a34cacd568d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9214dcfdb51c4ff090c8e0158913dc4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b42bffb3289d49b499b0e4934609b8e5": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_9214dcfdb51c4ff090c8e0158913dc4e",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 8/9  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">1177/1177</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:55 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">21.65it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">v_num: 3.000 train_loss: 0.084   </span>\n                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">valid_loss: 0.132 valid_accuracy:</span>\n                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.945 train_accuracy: 0.932      </span>\n</pre>\n",
         "text/plain": "Epoch 8/9  \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m1177/1177\u001b[0m \u001b[38;5;245m0:00:55 • 0:00:00\u001b[0m \u001b[38;5;249m21.65it/s\u001b[0m \u001b[37mv_num: 3.000 train_loss: 0.084   \u001b[0m\n                                                                                  \u001b[37mvalid_loss: 0.132 valid_accuracy:\u001b[0m\n                                                                                  \u001b[37m0.945 train_accuracy: 0.932      \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "dbbd7b77393b4807a29de8c8d3a154d2": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_717cf9cf0d6f4c0391e3a34cacd568d8",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 4/9  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">2354/2354</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:01:39 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">23.61it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">v_num: 2.000 train_loss: 0.613   </span>\n                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">valid_loss: 0.148 valid_accuracy:</span>\n                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">0.945 train_accuracy: 0.918      </span>\n</pre>\n",
         "text/plain": "Epoch 4/9  \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m2354/2354\u001b[0m \u001b[38;5;245m0:01:39 • 0:00:00\u001b[0m \u001b[38;5;249m23.61it/s\u001b[0m \u001b[37mv_num: 2.000 train_loss: 0.613   \u001b[0m\n                                                                                  \u001b[37mvalid_loss: 0.148 valid_accuracy:\u001b[0m\n                                                                                  \u001b[37m0.945 train_accuracy: 0.918      \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
